{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug Server",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/server.py",
            "cwd": "${workspaceFolder}",
            "env": {
                // "CUDA_LAUNCH_BLOCKING": "1"
                "CUDA_VISIBLE_DEVICES": "0",
            },
            "args": [
                "--model-dir",
                // "${workspaceFolder}/models",
                "${env:HOME}/models",

                "--model",
                // "llama3ins-8b-32k-q8.gguf",
                // "meta-llama-3-8b-instruct",
                "llama-3-8b-f16.gguf",

                // llama.cpp
                "--n_ctx",
                "8192",
                // "16384",
                "--n-gpu-layers",
                "1000",
                "--flash-attn",
                "--tensorcores",

                // // huggingface
                // // "--load-in-4bit",
                // "--use_flash_attention_2",
                // "--trust-remote-code",

                // // finetuned
                // "--lora-dir",
                // // "../llms/finetuning/checkpoints/2024-01-05-18-43-33-agent-instruct",
                // "../llms/finetuning/checkpoints/2024-01-21-21-21-49-TomGrc_FusionNet_7Bx2_MoE_14B-agent-instruct",
                // "--lora",
                // "checkpoint-200",

                "--api",
                "--api-port",
                "9002",
                "--listen",
                // "ngrok"
            ],
            "justMyCode": false,
            "python": "${command:python.interpreterPath}",
        },
        {
            "name": "Current",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "cwd": "${workspaceFolder}",
            "python": "${command:python.interpreterPath}",
            "justMyCode": false
        }
    ]
}